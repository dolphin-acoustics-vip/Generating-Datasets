{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating spectrograms from waveform data\n",
    "\n",
    "reference: https://github.com/JoshWheeler08/DolphinAcoustics-Classifier\n",
    "\n",
    "This jupyter notebook is for everything related to generating spectrograms: including functions that fetch your input files, functions that generate spectrograms from an input wav form and saves them to a specified output file path.\n",
    "\n",
    "This code is fully os-independent and fs-independent, so you don't have to worry whether you are running on a windows os or IOS or linux, they will all work. But do make sure you set up a virtual environment correctly before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you installed all the dependencies already, ignore this block of code\n",
    "!pip3 install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code block is a Configurations/Settings block for the processing part of this file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure parameters as you wish, currently they are equal to the default values in the function signature of save_spectrogram_image\n",
    "SAMPLING_RATE = 48000  # gemma's improved sampling rate\n",
    "FFT_NUM = 512  # fft number\n",
    "DPI = 96  # dots per inch of your screen, explained ahead why this is important\n",
    "MAX_FREQ = 22000\n",
    "MIN_FREQ = 3000\n",
    "IMAGE_SIZE = (413, 202) # (x, y)\n",
    "REF = np.max # save a function or a value that will act as a reference point in the amplitude_to_db function\n",
    "CLIM_LO = np.mean # this will be the lower bound of the color compression in the plotting function.\n",
    "CLIM_HI = 0 # this will be the upper bound of the color compression in the plotting function.\n",
    " \n",
    "# https://librosa.org/doc/main/generated/librosa.amplitude_to_db.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for generating and saving spectrograms and finding clips in the file system.\n",
    "\n",
    "The following code-block declares and defines functions for generating and saving spectrograms and finding clips in the file system.\n",
    "NB: matplotlib only works with real dimensions and not directly with pixels. So if you want to show or save an image of certain pixel you need to find out what dpi your screen uses.\n",
    "\n",
    "The following link allows you to detect the dpi of your screen:\n",
    "https://www.infobyip.com/detectmonitordpi.php\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spectrogram_image(\n",
    "    input_path,\n",
    "    output_path,\n",
    "    image_name,\n",
    "    sampling_rate=48000,\n",
    "    n_fft=512,\n",
    "    dpi=96,\n",
    "    max_freq=22000,\n",
    "    min_freq=3000,\n",
    "    img_size=(413, 202),\n",
    "    ref=np.max,\n",
    "    clim_lo=np.mean,\n",
    "    clim_hi=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    This function takes in the above parameters and\n",
    "    generates a spectrogram from a given sample recording passed in by the \"input_path\" and\n",
    "    saves the spectrogram image in \"output_path\" with the name \"image_name\".\n",
    "    -----------\n",
    "    Arguments:\n",
    "\n",
    "    - sampling_rate and n_fft variables are core variables that are used in the process of spectrogram generation.\n",
    "    - dpi is the dots per inch of your screen.\n",
    "    - max_freq and min_freq are used for cropping the image vertically, this is to cut off some artefacts resulting from low and high pass filters.\n",
    "    - img_size should be the desired size of the saved images.\n",
    "    - ref is the function/value you are using as a reference for fixing the zero in the amplitude_to_db function.\n",
    "    (If ref is changed, you probably want to change the clim parameters as well, as the default ones were designed\n",
    "    to work with np.max as a reference point.)\n",
    "    - clim_lo will be used as the lower bound of the color limit compression range.\n",
    "    - clim_hi will be used as the upper bound of the color limit compression range.\n",
    "    (If a function is passed in ie np.mean, it will be resolved in this code by calling it on the decibel-converted data)\n",
    "    -----------\n",
    "    Return:\n",
    "    \n",
    "    - save_path the path in which the image was saved (this can be useful for debugging and for checking that all images have been save correctly but the return line could be deleted if you trust the process)\n",
    "    \"\"\"\n",
    "\n",
    "    # get the max and min bins for cropping\n",
    "    f_step = sampling_rate / n_fft\n",
    "    min_bin = int(min_freq / f_step)\n",
    "    max_bin = int(max_freq / f_step)\n",
    "\n",
    "    # the user can decide whether they want to pass in a function or a variable for the color range compression,\n",
    "    # therefore we need to resolve the passed in parameters accordingly as such:\n",
    "    clim_lo = clim_lo(Ydb) if callable(clim_lo) else clim_lo\n",
    "    clim_hi = clim_hi(Ydb) if callable(clim_hi) else clim_hi\n",
    "    clim = [clim_lo, clim_hi]\n",
    "\n",
    "    # load wav file, apply short-time-fourier-transform, and crop the 2d array vertically, removing unwanted rows in the data.\n",
    "    y, sr = librosa.load(input_path, sr=sampling_rate)\n",
    "    Y = librosa.stft(y, n_fft=n_fft)\n",
    "    Y = Y[min_bin:max_bin, : ]  # Crop image vertically (frequency axis) from min_bin to max_bin\n",
    "\n",
    "    # change the amplitude from a linear scale to decibel scale (logarithmic)\n",
    "    Ydb = librosa.amplitude_to_db(abs(Y), ref=ref)\n",
    "    # initialise plot\n",
    "    fig = plt.figure(frameon=False, figsize=(img_size[0] / dpi, img_size[1] / dpi), dpi=dpi)\n",
    "    # remove axes from the plot\n",
    "    ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    \n",
    "    # plot the spectrogram on figure object in gray_r color mapping.\n",
    "    librosa.display.specshow(\n",
    "        Ydb, cmap=\"gray_r\", sr=sr, x_axis=\"time\", y_axis=\"hz\", clim=clim\n",
    "    )\n",
    "\n",
    "    # Save image at \"output_path/img_name.png\"\n",
    "    save_path = os.path.join(output_path, str(image_name) + \".png\")\n",
    "    fig.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def get_all_wavfiles(root_path):\n",
    "    \"\"\"\n",
    "    File-system independent function for getting all the wav files from the given root directory.\n",
    "    This will recursively get all the wav files.\n",
    "    Use walk function from the os module to get the root, dir and files in the given root_path.\n",
    "    Extract all paths to files and returns them in a generator so that it can be iterated over in a loop.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file_name in files:\n",
    "            path = os.path.join(root, file_name)\n",
    "            if path.endswith(\".wav\"):\n",
    "                yield (path)\n",
    "        for dir_name in dirs:\n",
    "            path = os.path.join(root, dir_name)\n",
    "            get_all_wavfiles(path)\n",
    "\n",
    "\n",
    "def create_storage_for_images(directory_to_store_images):\n",
    "    \"\"\"\n",
    "    Create storage for images under the path \"directory_to_store_images\" with shutil and os libraries.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory_to_store_images):\n",
    "        shutil.rmtree(directory_to_store_images)\n",
    "    os.makedirs(directory_to_store_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable code that loops through the given input path and saves generated spectrograms in output path\n",
    "\n",
    "### !!! Make sure your input file directory has folders under the same name of the species declared in the SPECIES array !!!\n",
    "Your input directory should look like this:\n",
    "\n",
    "                 root_path\n",
    "                /   ....   \\\n",
    "               /    ....    \\\n",
    "        specie_1            specie_N\n",
    "       / ..... \\ / ..... \\ / ..... \\ \n",
    "    [ any other subfolders can go here ]\n",
    "\n",
    "The following code block allows you to specify a path to your inputs (CLIPS_PATH) and a path to where you want to save the outputs (SAVE_IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input and download paths here.\n",
    "# the path module is operating sytem independent, it can create a posix path or a windows path.\n",
    "CLIPS_PATH = Path(\"/Users/matteohe/Desktop/DA/matteo\").resolve() # path to where you stored input wav-clips of dolphin sounds/whistles.\n",
    "SAVE_IMAGE_PATH = Path(\"/Users/matteohe/Desktop/DA/matteo_images\") # path to where you want to save your images.\n",
    "\n",
    "# specify the classes of species there are in your input data here\n",
    "SPECIES = [\"common\", \"bottlenose\", \"melon-headed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the count as the image name so that we can check if any of them were left out after the execution\n",
    "# this also allows the user to easily check if the data prior to the train-test split was shuffled or not\n",
    "count = 0\n",
    "\n",
    "#! make sure your input file directory has folders under the name of the species declared in the species array.\n",
    "for specie in SPECIES:\n",
    "\n",
    "    curr_input_dir = os.path.join(CLIPS_PATH, specie)\n",
    "    curr_output_dir = os.path.join(SAVE_IMAGE_PATH, specie)\n",
    "    create_storage_for_images(curr_output_dir)\n",
    "\n",
    "    for clip_path in get_all_wavfiles(curr_input_dir):\n",
    "        if not clip_path.endswith(\".wav\"):  # defensive code, steps over any files that does not have the .wav ending\n",
    "            continue\n",
    "        save_spectrogram_image(\n",
    "            clip_path,\n",
    "            curr_output_dir,\n",
    "            count,\n",
    "            SAMPLING_RATE,\n",
    "            FFT_NUM,\n",
    "            DPI,\n",
    "            MAX_FREQ, \n",
    "            MIN_FREQ, \n",
    "            IMAGE_SIZE,\n",
    "            REF,\n",
    "        )\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset of the generated spectrograms into training and testing folders.\n",
    "\n",
    "This automatic method of splitting data sets can help you generate datasets ready for training in the whistle_classifier file. \n",
    "\n",
    "The following code block defines the functions relevant for the splitting part of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_from_folder(path):\n",
    "    \"\"\"\n",
    "    Take in a root path and gets all the paths under that root path. Return the files as a numpy array.\n",
    "    Note that although this is very similar to the get_all_wavfiles, we cannot reuse that function as that is a generator function.\n",
    "    Here we need to return a numpy array so that we can count how much data we have to carry out proportional splitting of the data.\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    return np.asarray(files)\n",
    "\n",
    "\n",
    "def generate_training_and_testing_datasets(\n",
    "    path_to_data, path_to_test_data, train_test_ratio=0.6\n",
    "):\n",
    "    \"\"\"\n",
    "    This void function essentially splits a given complete dataset into two by randomly selecting a proportional number of files from the original folder and moving them into a test folder.\n",
    "    ---------\n",
    "    Arguments:\n",
    "\n",
    "    Takes in a path_to_data which is the input path of where all the spectrogram images are stored, and\n",
    "    path_to_test_data which is where you want to move images into the test folders.\n",
    "    The train_test_ratio specifies the desired ratio of the split.\n",
    "    \"\"\"\n",
    "\n",
    "    # counts all data per species\n",
    "    _, dirs, _ = next(os.walk(path_to_data))\n",
    "    counter_per_species = np.zeros((len(dirs)))  # counter array for data\n",
    "    for i in range(len(dirs)):\n",
    "        path = os.path.join(path_to_data, dirs[i])\n",
    "        files = get_files_from_folder(path)\n",
    "        counter_per_species[i] = len(files)  # save the count of files in the counter array\n",
    "\n",
    "    # calculate the number of files that need to be moved into a new testing folder with the desired split ratio\n",
    "    test_counter = np.round(counter_per_species * (1 - train_test_ratio))\n",
    "\n",
    "    # transfers files\n",
    "    for i in range(len(dirs)):\n",
    "        path_to_original = os.path.join(path_to_data, dirs[i])\n",
    "        path_to_save = os.path.join(path_to_test_data, dirs[i])\n",
    "\n",
    "        # creates directories\n",
    "        create_storage_for_images(path_to_save)\n",
    "        # if you did not run the code block that defined the function create_storage_for_images, comment the above line out and uncomment following lines of code:\n",
    "        # if not os.path.exists(path_to_save):\n",
    "        #     os.makedirs(path_to_save)\n",
    "\n",
    "        files = get_files_from_folder(path_to_original)  # this returns a numpy array with the paths of the files we wish to move\n",
    "        np.random.shuffle(files)  # shuffle the numpy array of file paths, this is to remove any proximity bias of the files (whistles) which has been a recurrent issue in previous semesters\n",
    "\n",
    "        # moves data\n",
    "        for j in range(int(test_counter[i])):\n",
    "            dst = os.path.join(path_to_save, files[j])\n",
    "            src = os.path.join(path_to_original, files[j])\n",
    "            shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following executable code for splitting the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = Path(\"test-data\")\n",
    "TRAIN_TEST_RATIO = 0.7\n",
    "\n",
    "generate_training_and_testing_datasets(SAVE_IMAGE_PATH, TEST_DATA, TRAIN_TEST_RATIO)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "039371b77139fa2b9bd518eca1b62ab7d3ddf0505b49296a18c58435d742de7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('dolphins': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
